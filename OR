import pandas as pd

def find_duplicates_same_wage_diff_sector(df):
    """
    Returns rows where the same ID appears with the exact same WAGE
    but different SECTOR values.
    """
    # Group by ID and WAGE and filter those with more than one unique SECTOR
    filtered = df.groupby(['ID', 'WAGE'])['SECTOR'].nunique().reset_index()
    filtered = filtered[filtered['SECTOR'] > 1][['ID', 'WAGE']]

    # Merge back to original to get full rows
    result = df.merge(filtered, on=['ID', 'WAGE'])
    return result.sort_values(by=['ID', 'WAGE'])

# Example usage:
# result = find_duplicates_same_wage_diff_sector(your_dataframe)



import pandas as pd
import us
from concurrent.futures import ThreadPoolExecutor, as_completed

def count_ui_naics_multi_by_level():
    """
    For each yr_qtr, state, and NAICS level (2 to 6), count:
    - UIs with only one unique NAICS (single)
    - UIs with multiple NAICS (multi)
    - Compute % breakdown

    Returns a DataFrame:
    ['yr_qtr', 'state', 'naics_level', 'single_ui_count', 'multi_ui_count', 'total_ui', 'pct_single', 'pct_multi']
    """

    def process_dom(year, fips):
        try:
            df = DOM2(year, fips)
            df = df[['yr_qtr', 'state', 'UI', 'naics2', 'naics3', 'naics4', 'naics5', 'naics6']].dropna()
            df = df.astype({lvl: str for lvl in ['naics2', 'naics3', 'naics4', 'naics5', 'naics6']})

            summaries = []

            for level in ['naics2', 'naics3', 'naics4', 'naics5', 'naics6']:
                grouped = df.groupby(['yr_qtr', 'state', 'UI'])[level].nunique().reset_index()
                grouped['ui_type'] = grouped[level].apply(lambda x: 'single' if x == 1 else 'multi')

                summary = (
                    grouped.groupby(['yr_qtr', 'state', 'ui_type'])['UI']
                    .nunique()
                    .unstack(fill_value=0)
                    .reset_index()
                    .rename(columns={'single': 'single_ui_count', 'multi': 'multi_ui_count'})
                )

                summary['naics_level'] = level
                summary['single_ui_count'] = summary.get('single_ui_count', 0)
                summary['multi_ui_count'] = summary.get('multi_ui_count', 0)
                summary['total_ui'] = summary['single_ui_count'] + summary['multi_ui_count']
                summary['pct_single'] = 100 * summary['single_ui_count'] / summary['total_ui']
                summary['pct_multi'] = 100 * summary['multi_ui_count'] / summary['total_ui']

                summaries.append(summary)

            return pd.concat(summaries, ignore_index=True)

        except Exception as e:
            print(f"Error processing year={year}, fips={fips}: {e}")
            return pd.DataFrame(columns=[
                'yr_qtr', 'state', 'single_ui_count', 'multi_ui_count',
                'total_ui', 'pct_single', 'pct_multi', 'naics_level'
            ])

    # Build jobs
    year_range = range(2020, 2025)
    fips_list = [state.fips for state in us.states.STATES if state.fips is not None]
    jobs = [(year, fips) for year in year_range for fips in fips_list]

    # Multithreaded execution
    all_results = []
    with ThreadPoolExecutor(max_workers=10) as executor:
        futures = [executor.submit(process_dom, year, fips) for year, fips in jobs]
        for future in as_completed(futures):
            result = future.result()
            if not result.empty:
                all_results.append(result)

    # Combine and group totals
    final_df = pd.concat(all_results, ignore_index=True)
    final_df = (
        final_df.groupby(['yr_qtr', 'state', 'naics_level'], as_index=False)
        .agg({
            'single_ui_count': 'sum',
            'multi_ui_count': 'sum',
            'total_ui': 'sum'
        })
    )
    final_df['pct_single'] = 100 * final_df['single_ui_count'] / final_df['total_ui']
    final_df['pct_multi'] = 100 * final_df['multi_ui_count'] / final_df['total_ui']

    return final_df
