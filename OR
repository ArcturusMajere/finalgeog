def summarize_6244_flows(df,cohort_qtr='2020-1',sector_code='6244',filename='6244_flows.xlsx'):
    sub=df[df['yr_qtr']>=cohort_qtr]
    orig=sub.loc[(sub['yr_qtr']==cohort_qtr)&(sub['sector']==sector_code),'count'].sum()
    st=sub.groupby(['yr_qtr','state'])['count'].sum().reset_index(name='count')
    st['pct']=st['count']/orig
    swr=st.pivot('yr_qtr','state','count').fillna(0).reset_index()
    swp=st.pivot('yr_qtr','state','pct').fillna(0).reset_index()
    sc=sub.groupby(['yr_qtr','sector'])['count'].sum().reset_index(name='count')
    sc['pct']=sc['count']/orig
    secw=sc.pivot('yr_qtr','sector','count').fillna(0).reset_index()
    secp=sc.pivot('yr_qtr','sector','pct').fillna(0).reset_index()
    with pd.ExcelWriter(filename) as writer:
        st.to_excel(writer,'state_trans',index=False)
        swr.to_excel(writer,'state_raw_wide',index=False)
        swp.to_excel(writer,'state_pct_wide',index=False)
        sc.to_excel(writer,'sector_trans',index=False)
        secw.to_excel(writer,'sector_raw_wide',index=False)
        secp.to_excel(writer,'sector_pct_wide',index=False)
    return st,swr,swp,sc,secw,secp



import pandas as pd

def summarize_6244_state_flows(
    df,
    cohort_qtr: str = '2020-1',
    sector_code: str = '6244'
):
    """
    From an aggregated df of cohort counts, compute raw and normalized state 
    distributions of the sector 6244 cohort over time.
    
    Parameters
    ----------
    df : pd.DataFrame
        Aggregated counts with columns:
        ['yr_qtr','state','sector','original_class','current_class','count']
        This df must already only contain rows for the cohort individuals
        (i.e. everyone in sector_code at cohort_qtr and their counts by state
        & quarter).
    cohort_qtr : str
        The quarter defining the base cohort (default '2020-1').
    sector_code : str
        The sector code of interest (default '6244').
    
    Returns
    -------
    state_trans : pd.DataFrame
        Long table with columns ['yr_qtr','state','raw_count','pct_of_cohort'].
    state_wide_raw : pd.DataFrame
        Pivoted table (rows=yr_qtr, cols=state) of raw counts.
    state_wide_pct : pd.DataFrame
        Pivoted table of normalized shares of the original cohort.
    """
    # 1. Filter to the sector and all quarters ≥ cohort_qtr
    sub = df.loc[
        (df['sector'] == sector_code) &
        (df['yr_qtr'] >= cohort_qtr),
        ['yr_qtr','state','count']
    ].copy()
    
    # 2. Compute the cohort's original size in cohort_qtr
    orig_size = (
        sub.loc[sub['yr_qtr'] == cohort_qtr, 'count']
        .sum()
    )
    
    # 3. Summarize raw counts by quarter & state
    state_trans = (
        sub
        .groupby(['yr_qtr','state'])['count']
        .sum()
        .reset_index(name='raw_count')
        .sort_values(['yr_qtr','raw_count'], ascending=[True, False])
    )
    
    # 4. Compute normalized share of the original cohort
    state_trans['pct_of_cohort'] = state_trans['raw_count'] / orig_size
    
    # 5. Pivot to wide format
    state_wide_raw = (
        state_trans
        .pivot(index='yr_qtr', columns='state', values='raw_count')
        .fillna(0)
        .reset_index()
    )
    state_wide_pct = (
        state_trans
        .pivot(index='yr_qtr', columns='state', values='pct_of_cohort')
        .fillna(0)
        .reset_index()
    )
    
    return state_trans, state_wide_raw, state_wide_pct

# Example usage:
# state_trans, raw_wide, pct_wide = summarize_6244_state_flows(df)
# print(state_trans.head())
# print(raw_wide.head())
# print(pct_wide.head())

import pandas as pd

# Assume df is your DataFrame with columns:
# ['yr_qtr', 'state', 'sector', 'original_class', 'current_class', 'count']

# 1. Raw summaries

# 1a. Total count by yr_qtr & state
state_raw = (
    df
    .groupby(['yr_qtr', 'state'])['count']
    .sum()
    .reset_index()
    .sort_values(['yr_qtr', 'state'])
)

# 1b. Total count by yr_qtr & sector
sector_raw = (
    df
    .groupby(['yr_qtr', 'sector'])['count']
    .sum()
    .reset_index()
    .sort_values(['yr_qtr', 'sector'])
)

# 1c. Class‐transition counts by yr_qtr & state
ct = (
    df
    .groupby(['yr_qtr', 'state', 'original_class', 'current_class'])['count']
    .sum()
    .reset_index()
)
transition_raw = (
    ct
    .assign(transition=lambda d: d['original_class'] + '→' + d['current_class'])
    .pivot_table(
        index=['yr_qtr', 'state'],
        columns='transition',
        values='count',
        fill_value=0
    )
    .reset_index()
    .sort_values(['yr_qtr', 'state'])
)

# 2. Normalized summaries

# 2a. Normalize state totals within each yr_qtr
state_norm = state_raw.copy()
state_norm['pct_of_quarter'] = (
    state_norm.groupby('yr_qtr')['count']
    .apply(lambda s: s / s.sum())
)

# 2b. Normalize sector totals within each yr_qtr
sector_norm = sector_raw.copy()
sector_norm['pct_of_quarter'] = (
    sector_norm.groupby('yr_qtr')['count']
    .apply(lambda s: s / s.sum())
)

# 2c. Normalize class‐transition flows within each yr_qtr & state
transition_norm = transition_raw.copy()
flow_cols = [c for c in transition_norm.columns if '→' in c]
transition_norm[flow_cols] = (
    transition_norm[flow_cols]
    .div(transition_norm[flow_cols].sum(axis=1), axis=0)
)

# 3. Display or export
print("=== Raw: Total by Quarter & State ===")
print(state_raw)

print("\n=== Normalized: Total by Quarter & State ===")
print(state_norm)

print("\n=== Raw: Total by Quarter & Sector ===")
print(sector_raw)

print("\n=== Normalized: Total by Quarter & Sector ===")
print(sector_norm)

print("\n=== Raw: Class Transitions by Quarter & State ===")
print(transition_raw)

print("\n=== Normalized: Class Transitions by Quarter & State ===")
print(transition_norm)


import pandas as pd
import matplotlib.pyplot as plt

# Assuming df is already loaded

# --- Compute summaries ---

# Total count by quarter & state
state_raw = df.groupby(['yr_qtr', 'state'])['count'].sum().reset_index().sort_values(['yr_qtr', 'state'])

# Total count by quarter & sector
sector_raw = df.groupby(['yr_qtr', 'sector'])['count'].sum().reset_index().sort_values(['yr_qtr', 'sector'])

# Class-transition counts
ct = df.groupby(['yr_qtr', 'state', 'original_class', 'current_class'])['count'].sum().reset_index()
transition_raw = ct.assign(
    transition=ct['original_class'] + '→' + ct['current_class']
).pivot_table(
    index=['yr_qtr', 'state'],
    columns='transition',
    values='count',
    fill_value=0
).reset_index().sort_values(['yr_qtr', 'state'])

flow_cols = [c for c in transition_raw.columns if '→' in c]

# --- 1. Cohort size over time (all states) ---
total_by_q = state_raw.groupby('yr_qtr')['count'].sum()
plt.figure()
plt.plot(total_by_q.index, total_by_q.values, marker='o')
plt.title('Total Cohort Size Over Time')
plt.xlabel('Quarter')
plt.ylabel('Count')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# --- 2. Top 3 states cohort trends ---
state_totals = state_raw.groupby('state')['count'].sum()
top_states = state_totals.nlargest(3).index
for s in top_states:
    sub = state_raw[state_raw['state'] == s]
    plt.figure()
    plt.plot(sub['yr_qtr'], sub['count'], marker='o')
    plt.title(f'{s}: Cohort Size Over Time')
    plt.xlabel('Quarter')
    plt.ylabel('Count')
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()

# --- 3. Top 10 sectors in the last quarter ---
last_q = sector_raw['yr_qtr'].max()
sub_sec = sector_raw[sector_raw['yr_qtr'] == last_q].nlargest(10, 'count')
plt.figure()
plt.bar(sub_sec['sector'], sub_sec['count'])
plt.title(f'Top 10 Sectors in {last_q}')
plt.xlabel('Sector')
plt.ylabel('Count')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# --- 4. Heatmap of class transitions for last quarter (aggregated across states) ---
trans_last = ct[ct['yr_qtr'] == last_q].groupby(['original_class', 'current_class'])['count'].sum().unstack()
plt.figure()
plt.imshow(trans_last, aspect='auto')
plt.xticks(range(len(trans_last.columns)), trans_last.columns)
plt.yticks(range(len(trans_last.index)), trans_last.index)
plt.colorbar(label='Count')
plt.title(f'Class Transitions ({last_q})')
plt.xlabel('Current Class')
plt.ylabel('Original Class')
plt.tight_layout()
plt.show()

# --- 5. Stacked bar: aggregate class transitions in last quarter ---
agg_flows = trans_last.fillna(0)
plt.figure()
agg_flows.plot(kind='bar', stacked=True)
plt.title(f'Aggregate Class Transitions in {last_q}')
plt.xlabel('Original Class')
plt.ylabel('Count')
plt.xticks(rotation=0)
plt.tight_layout()
plt.show()

# --- 6. Static bubble plot for last quarter ---
# Prepare data
bubble = ct[ct['yr_qtr'] == last_q]
plt.figure()
plt.scatter(
    bubble['original_class'], bubble['current_class'], 
    s=bubble['count'] / bubble['count'].max() * 1000, 
    alpha=0.6
)
plt.title(f'Bubble Plot of Transitions in {last_q}')
plt.xlabel('Original Class')
plt.ylabel('Current Class')
plt.tight_layout()
plt.show()



















import pandas as pd
def compute_summary_stats_pivot(xlsx_path):
    xls=pd.ExcelFile(xlsx_path)
    df=pd.concat([pd.read_excel(xls,sheet_name=sh).assign(state=sh) for sh in xls.sheet_names],ignore_index=True)
    keys=df[df['yr_qtr']=='2020-1'][['state','sector','original_class']].drop_duplicates()
    dfc=df.merge(keys,on=['state','sector','original_class'],how='inner')
    state_totals=dfc.groupby(['state','yr_qtr'],as_index=False)['count'].sum().rename(columns={'count':'state_total'}).pivot(index='state',columns='yr_qtr',values='state_total').reset_index()
    sector_totals=df.groupby(['sector','yr_qtr'],as_index=False)['count'].sum().rename(columns={'count':'sector_total'}).pivot(index='sector',columns='yr_qtr',values='sector_total').reset_index()
    d4=dfc[dfc['sector']=='6244'].groupby(['state','yr_qtr'],as_index=False)['count'].sum()
    orig4=d4[d4['yr_qtr']=='2020-1'][['state','count']].rename(columns={'count':'orig_6244'})
    sector_6244_counts=d4.merge(orig4,on='state').pivot(index='state',columns='yr_qtr',values='count').reset_index()
    sector_6244_change=d4.merge(orig4,on='state').assign(change=lambda d:d['count']-d['orig_6244']).pivot(index='state',columns='yr_qtr',values='change').reset_index()
    orig_tot=dfc[dfc['yr_qtr']=='2020-1'].groupby('state',as_index=False)['count'].sum().rename(columns={'count':'orig_total'})
    cohort_tot=dfc.groupby(['state','yr_qtr'],as_index=False)['count'].sum().rename(columns={'count':'cohort_total'})
    unfound=cohort_tot.merge(orig_tot,on='state').assign(unfound=lambda d:d['orig_total']-d['cohort_total']).pivot(index='state',columns='yr_qtr',values='unfound').reset_index()
    return{'state_totals':state_totals,'sector_totals':sector_totals,'sector_6244_counts':sector_6244_counts,'sector_6244_change':sector_6244_change,'unfound':unfound}
if __name__=='__main__':
    sums=compute_summary_stats_pivot("cohort_tracking.xlsx")
    with pd.ExcelWriter("summary_stats_pivot.xlsx",engine="xlsxwriter") as w:
        for k,df in sums.items():df.to_excel(w,sheet_name=k,index=False)

def compute_summary_stats_pivot(xlsx_path):
    xls=pd.ExcelFile(xlsx_path)
    df=pd.concat([pd.read_excel(xls,sheet_name=sh).assign(state=sh) for sh in xls.sheet_names],ignore_index=True)
    keys=df[df['yr_qtr']=='2020-1'][['state','sector','original_class']].drop_duplicates()
    dfc=df.merge(keys,on=['state','sector','original_class'],how='inner')
    st=dfc.groupby(['state','yr_qtr'],as_index=False)['count'].sum().rename(columns={'count':'state_total'})
    sg=dfc.groupby(['sector','yr_qtr'],as_index=False)['count'].sum().rename(columns={'count':'sector_total'})
    d4=dfc[dfc['sector']=='6244'].groupby(['state','yr_qtr'],as_index=False)['count'].sum()
    o4=d4[d4['yr_qtr']=='2020-1'][['state','count']].rename(columns={'count':'orig_6244'})
    s4=d4.merge(o4,on='state').assign(change=lambda d:d['count']-d['orig_6244'])
    ot=dfc[dfc['yr_qtr']=='2020-1'].groupby('state',as_index=False)['count'].sum().rename(columns={'count':'orig_total'})
    ct=dfc.groupby(['state','yr_qtr'],as_index=False)['count'].sum().rename(columns={'count':'cohort_total'})
    uf=ct.merge(ot,on='state').assign(unfound=lambda d:d['orig_total']-d['cohort_total'])
    return {
        'state_totals':st.pivot(index='state',columns='yr_qtr',values='state_total').reset_index(),
        'sector_totals':sg.pivot(index='sector',columns='yr_qtr',values='sector_total').reset_index(),
        'sector_6244_counts':d4.pivot(index='state',columns='yr_qtr',values='count').reset_index(),
        'sector_6244_change':s4.pivot(index='state',columns='yr_qtr',values='change').reset_index(),
        'unfound':uf.pivot(index='state',columns='yr_qtr',values='unfound').reset_index()
    }

if __name__=='__main__':
    sums=compute_summary_stats_pivot("cohort_tracking.xlsx")
    with pd.ExcelWriter("summary_stats_pivot.xlsx",engine="xlsxwriter") as w:
        for name,df in sums.items():
            df.to_excel(w,sheet_name=name,index=False)


import pandas as pd

def compute_summary_stats(xlsx_path: str):
    """
    Reads an Excel workbook with sheets named by state abbrev, each having
    columns [yr_qtr, state, sector, original_class, current_class, count].
    Filters to the 2020-1 cohort, then computes:
    
      1) state_totals:   total count per state & yr_qtr
      2) sector_totals:  total count per sector & yr_qtr
      3) sector_6244_changes:
            - count of sector '6244' per state & yr_qtr
            - change = count – orig_6244 (where orig_6244 is its 2020-1 count)
      4) unfound:
            - orig_total = total cohort count in 2020-1 per state
            - cohort_total = cohort count per state & yr_qtr
            - unfound = orig_total – cohort_total
    
    Returns
    -------
    dict of DataFrames:
      {
        'state_totals': pd.DataFrame,
        'sector_totals': pd.DataFrame,
        'sector_6244_changes': pd.DataFrame,
        'unfound': pd.DataFrame
      }
    """
    # 1) load & stack all sheets, tagging each row with sheet_name
    xls = pd.ExcelFile(xlsx_path)
    df = pd.concat(
        [pd.read_excel(xls, sheet_name=sh).assign(state=sh)
         for sh in xls.sheet_names],
        ignore_index=True
    )

    # 2) identify the 2020-1 cohort keys and filter to just that cohort
    cohort_keys = (
        df[df['yr_qtr']=='2020-1']
        .loc[:, ['state','sector','original_class']]
        .drop_duplicates()
    )
    df_cohort = df.merge(cohort_keys, on=['state','sector','original_class'], how='inner')

    # 3) state_totals
    state_totals = (
        df_cohort
        .groupby(['state','yr_qtr'], as_index=False)['count']
        .sum()
        .rename(columns={'count':'state_total'})
    )

    # 4) sector_totals
    sector_totals = (
        df_cohort
        .groupby(['sector','yr_qtr'], as_index=False)['count']
        .sum()
        .rename(columns={'count':'sector_total'})
    )

    # 5) sector_6244_changes
    df_6244 = df_cohort[df_cohort['sector']=='6244']
    sec = (
        df_6244
        .groupby(['state','yr_qtr'], as_index=False)['count']
        .sum()
    )
    # original 6244 counts per state at 2020-1
    orig_6244 = (
        sec[sec['yr_qtr']=='2020-1']
        .loc[:, ['state','count']]
        .rename(columns={'count':'orig_6244'})
    )
    sector_6244_changes = (
        sec
        .merge(orig_6244, on='state')
        .assign(change = lambda d: d['count'] - d['orig_6244'])
    )

    # 6) unfound: how many from the original cohort are NOT found in each quarter
    # 6a) original cohort total per state (all sectors & classes) at 2020-1
    orig_tot = (
        df_cohort[df_cohort['yr_qtr']=='2020-1']
        .groupby('state', as_index=False)['count']
        .sum()
        .rename(columns={'count':'orig_total'})
    )
    # 6b) cohort total per state & quarter
    cohort_tot = (
        df_cohort
        .groupby(['state','yr_qtr'], as_index=False)['count']
        .sum()
        .rename(columns={'count':'cohort_total'})
    )
    # 6c) merge and compute unfound
    unfound = (
        cohort_tot
        .merge(orig_tot, on='state')
        .assign(unfound=lambda d: d['orig_total'] - d['cohort_total'])
    )

    return {
        'state_totals': state_totals,
        'sector_totals': sector_totals,
        'sector_6244_changes': sector_6244_changes,
        'unfound': unfound
    }

# — example usage —
if __name__ == "__main__":
    summaries = compute_summary_stats("cohort_tracking.xlsx")
    for name, df in summaries.items():
        print(f"\n===== {name} =====")
        print(df.head().to_string(index=False))
