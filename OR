# Make sure your original query_ids_year_qtr function is imported or defined first

import time, statistics
from itertools import product

def bench(run_fn, ids, tries=2):
    times = []
    for _ in range(tries):
        start = time.time()
        run_fn(ids)
        times.append(time.time() - start)
    return statistics.median(times)

def tune(ids, start_year, start_qtr, end_year, end_qtr, dsn, user, password):
    worker_opts = [2, 4, 6, 8]
    chunk_opts = [250, 500, 800, 1000]
    results = []
    
    # Take a subset for testing so it runs quickly
    sample = ids[:100000]
    
    for w, c in product(worker_opts, chunk_opts):
        def runner(x):
            query_ids_year_qtr(
                x,
                start_year, start_qtr,
                end_year, end_qtr,
                dsn, user, password,
                file_dir="/dev/null",  # discard output for speed test
                workers=w, chunk_size=c
            )
        median_time = bench(runner, sample)
        rows_per_sec = len(sample) / median_time
        results.append((rows_per_sec, w, c, median_time))
    
    results.sort(reverse=True)
    return results

# Example usage:
ids_list = [i for i in range(1, 500000)]  # replace with your actual IDs
best_results = tune(
    ids_list,
    start_year=2023, start_qtr=1,
    end_year=2024, end_qtr=2,
    dsn="host:port/service",
    user="u", password="p"
)

print("Top configurations by rows/sec:")
for rps, w, c, t in best_results[:5]:
    print(f"Workers={w}, Chunk={c}, Rows/sec={rps:.0f}, Time={t:.2f}s")





import oracledb
import csv
from concurrent.futures import ThreadPoolExecutor, as_completed

def query_ids_year_qtr_concurrent(ids, start_year, start_qtr, end_year, end_qtr,
                                   dsn, user, password, file_dir,
                                   workers=6, chunk_size=1000):
    """
    Executes concurrent Oracle database queries using connection pooling and
    ThreadPoolExecutor to fetch data for given IDs within a specified year and quarter range.

    Args:
        ids (list): A list of IDs to query for.
        start_year (int): The starting year for the query.
        start_qtr (int): The starting quarter for the query.
        end_year (int): The ending year for the query.
        end_qtr (int): The ending quarter for the query.
        dsn (str): The Oracle Database DSN (Data Source Name).
        user (str): The Oracle Database username.
        password (str): The Oracle Database password.
        file_dir (str): The directory path to save the CSV output.
        workers (int): The number of worker threads to use in the ThreadPoolExecutor.
        chunk_size (int): The number of IDs to process in each query chunk.
    """

    # 1. Create the Oracle Connection Pool
    # Using oracledb.create_pool for the new connection pooling API.
    # It's recommended to set min and max to the same value for fixed-size pools, 
    # {Link: according to the oracledb Documentation https://python-oracledb.readthedocs.io/en/v2.4.1/user_guide/connection_handling.html}. 
    # Using POOL_GETMODE_WAIT ensures threads wait for an available connection if none are free.
    pool = oracledb.create_pool(user=user, password=password, dsn=dsn,
                                min=workers, max=workers, increment=0,
                                homogeneous=True, timeout=60, # Timeout for connections in the pool
                                getmode=oracledb.POOL_GETMODE_WAIT) # Wait for a connection if none are available

    # 2. Define the function to run in each thread (querying a chunk of IDs)
    def run_chunk(id_chunk):
        """
        Queries the database for a chunk of IDs within the specified year and quarter range.
        Acquires a connection from the pool and releases it back upon completion.
        """
        if not id_chunk:
            return []

        # Constructing the placeholder string for IN clause efficiently
        # Example: if id_chunk is [1, 2, 3], ph becomes ":id0,:id1,:id2"
        ph = ",".join([f":id{i}" for i in range(len(id_chunk))])
        params = {f"id{i}": v for i, v in enumerate(id_chunk)}
        params.update({"sy": start_year, "sq": start_qtr,
                       "ey": end_year, "eq": end_qtr})

        # The SQL query to retrieve data
        # Note: Replace 'your_table' with your actual table name
        sql = f"""
        SELECT id,
               fips,
               UI,
               run,
               wage,
               (TO_CHAR(year) || '-' || TO_CHAR(qtr)) AS yr_qtr
        FROM your_table
        WHERE id IN ({ph})
          AND (year > :sy OR (year = :sy AND qtr >= :sq))
          AND (year < :ey OR (year = :ey AND qtr <= :eq))
        """
        
        # Acquire a connection from the pool using a context manager for automatic release
        with pool.acquire() as conn:
            cur = conn.cursor()
            cur.execute(sql, params)
            return cur.fetchall()

    # 3. Divide the IDs into chunks for parallel processing
    chunks = [ids[i:i + chunk_size] for i in range(0, len(ids), chunk_size)]
    out = []

    # 4. Use ThreadPoolExecutor for concurrent execution of chunks
    # max_workers is set to 'workers' to utilize the specified number of threads.
    with ThreadPoolExecutor(max_workers=workers) as ex:
        # Submit each chunk to the executor for processing
        futs = [ex.submit(run_chunk, ch) for ch in chunks]
        # Iterate over completed futures and extend the results list
        for f in as_completed(futs):
            # as_completed() yields futures as they complete, allowing
            # results to be collected as soon as they are ready.
            out.extend(f.result())

    # 5. Close the connection pool when all tasks are complete
    pool.close()

    # 6. Save the results to a CSV file
    with open(file_dir, mode="w", newline="", encoding="utf-8") as f:
        writer = csv.writer(f)
        writer.writerow(["id", "fips", "UI", "run", "wage", "yr_qtr"]) # Header row
        writer.writerows(out)

# Example Usage:
if __name__ == "__main__":
    # Replace these with your actual database connection details and IDs
    sample_ids = list(range(1, 10001)) # Example: 10,000 IDs
    start_year = 2023
    start_qtr = 1
    end_year = 2024
    end_qtr = 2
    dsn = "hostname:port/service_name"  # e.g., "localhost:1521/XE"
    user = "your_username"
    password = "your_password"
    output_file = "output.csv"

    print("Starting concurrent database query...")
    query_ids_year_qtr_concurrent(
        ids=sample_ids,
        start_year=start_year,
        start_qtr=start_qtr,
        end_year=end_year,
        end_qtr=end_qtr,
        dsn=dsn,
        user=user,
        password=password,
        file_dir=output_file,
        workers=8, # Adjust the number of workers based on your system and database capacity
        chunk_size=500 # Adjust chunk size for optimal performance
    )
    print(f"Query complete. Results saved to {output_file}")
















import oracledb, math, csv
from concurrent.futures import ThreadPoolExecutor, as_completed

def query_ids_year_qtr(ids, start_year, start_qtr, end_year, end_qtr,
                       dsn, user, password, file_dir,
                       workers=6, chunk_size=1000):
    pool = oracledb.create_pool(user=user, password=password, dsn=dsn,
                                min=workers, max=workers, increment=0,
                                homogeneous=True, timeout=60,
                                getmode=oracledb.POOL_GETMODE_WAIT)
    def run_chunk(id_chunk):
        if not id_chunk:
            return []
        ph = ",".join([f":id{i}" for i in range(len(id_chunk))])
        params = {f"id{i}": v for i, v in enumerate(id_chunk)}
        params.update({"sy": start_year, "sq": start_qtr,
                       "ey": end_year, "eq": end_qtr})
        sql = f"""
        SELECT id,
               fips,
               UI,
               run,
               wage,
               (TO_CHAR(year) || '-' || TO_CHAR(qtr)) AS yr_qtr
        FROM your_table
        WHERE id IN ({ph})
          AND (year > :sy OR (year = :sy AND qtr >= :sq))
          AND (year < :ey OR (year = :ey AND qtr <= :eq))
        """
        with pool.acquire() as conn:
            cur = conn.cursor()
            cur.execute(sql, params)
            return cur.fetchall()

    chunks = [ids[i:i + chunk_size] for i in range(0, len(ids), chunk_size)]
    out = []
    with ThreadPoolExecutor(max_workers=workers) as ex:
        futs = [ex.submit(run_chunk, ch) for ch in chunks]
        for f in as_completed(futs):
            out.extend(f.result())

    pool.close()

    with open(file_dir, mode="w", newline="", encoding="utf-8") as f:
        writer = csv.writer(f)
        writer.writerow(["id", "fips", "UI", "run", "wage", "yr_qtr"])
        writer.writerows(out)

# Example usage (as provided in the original code):
# query_ids_year_qtr(
#     ids=[101, 205, 309],
#     start_year=2023, start_qtr=1,
#     end_year=2024, end_qtr=2,
#     dsn="host:port/service",
#     user="u", password="p",
#     file_dir="output.csv"
# )

##################################################
import oracledb

conn = oracledb.connect(user="username", password="password", dsn="host:port/service")
cur = conn.cursor()

id_list = [101, 205, 309]
start_year, start_qtr = 2023, 1
end_year, end_qtr = 2024, 2

id_placeholders = ",".join([f":id{i}" for i in range(len(id_list))])
params = {f"id{i}": v for i, v in enumerate(id_list)}
params.update({
    "start_year": start_year,
    "start_qtr": start_qtr,
    "end_year": end_year,
    "end_qtr": end_qtr
})

sql = f"""
SELECT id,
       fips,
       UI,
       run,
       wage,
       (TO_CHAR(year) || '-' || TO_CHAR(qtr)) AS yr_qtr
FROM your_table
WHERE id IN ({id_placeholders})
  AND (
        year > :start_year 
        OR (year = :start_year AND qtr >= :start_qtr)
      )
  AND (
        year < :end_year 
        OR (year = :end_year AND qtr <= :end_qtr)
      )
"""

cur.execute(sql, params)
rows = cur.fetchall()
for r in rows:
    print(r)

cur.close()
conn.close()


#$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
import oracledb, math
from concurrent.futures import ThreadPoolExecutor, as_completed

def query_ids_year_qtr(ids, start_year, start_qtr, end_year, end_qtr,
                       dsn, user, password, workers=6, chunk_size=1000):
    pool = oracledb.SessionPool(user=user, password=password, dsn=dsn,
                                min=workers, max=workers, increment=0,
                                homogeneous=True, timeout=60,
                                getmode=oracledb.SPOOL_ATTRVAL_WAIT)

    def run_chunk(id_chunk):
        if not id_chunk:
            return []
        ph = ",".join([f":id{i}" for i in range(len(id_chunk))])
        params = {f"id{i}": v for i, v in enumerate(id_chunk)}
        params.update({"sy": start_year, "sq": start_qtr,
                       "ey": end_year, "eq": end_qtr})
        sql = f"""
        SELECT id,
               fips,
               UI,
               run,
               wage,
               (TO_CHAR(year) || '-' || TO_CHAR(qtr)) AS yr_qtr
        FROM your_table
        WHERE id IN ({ph})
          AND (year > :sy OR (year = :sy AND qtr >= :sq))
          AND (year < :ey OR (year = :ey AND qtr <= :eq))
        """
        with pool.acquire() as conn:
            cur = conn.cursor()
            cur.execute(sql, params)
            return cur.fetchall()

    chunks = [ids[i:i + chunk_size] for i in range(0, len(ids), chunk_size)]
    out = []
    with ThreadPoolExecutor(max_workers=workers) as ex:
        futs = [ex.submit(run_chunk, ch) for ch in chunks]
        for f in as_completed(futs):
            out.extend(f.result())

    pool.close()
    return out

# Example usage:
# rows = query_ids_year_qtr(
#     ids=[101, 205, 309],
#     start_year=2023, start_qtr=1,
#     end_year=2024, end_qtr=2,
#     dsn="host:port/service",
#     user="u", password="p"
# )
# print(rows)

def query_ids_year_qtr(
    ids,
    start_year,
    start_qtr,
    end_year,
    end_qtr,
    dsn,
    user,
    password,
    workers=6,
    chunk_size=1000
):
    """
    Retrieve records for specific IDs within a year–quarter timeframe using multithreaded Oracle DB queries.

    This function connects to an Oracle database via a session pool, splits the input IDs into chunks,
    and queries each chunk in parallel threads. It returns all rows from the table that match both:
      1) The IDs provided in `ids`
      2) The timeframe specified by (start_year, start_qtr) through (end_year, end_qtr)

    Each row returned includes:
      - id     : ID from the input list
      - fips   : Geographic FIPS code from the database
      - UI     : Unemployment Insurance account number
      - run    : Processing run identifier
      - wage   : Wage value
      - yr_qtr : Concatenated "YYYY-Q" string representing year and quarter

    Parameters
    ----------
    ids : list[int] or list[str]
        The list of IDs to match against the `id` column in the database.
        Can be very large; duplicates can be removed before calling to improve efficiency.

    start_year : int
        The first year of the timeframe filter (inclusive).
        Example: 2023

    start_qtr : int
        The first quarter of the timeframe filter within `start_year` (1–4).

    end_year : int
        The last year of the timeframe filter (inclusive).

    end_qtr : int
        The last quarter of the timeframe filter within `end_year` (1–4).

    dsn : str
        Oracle Data Source Name, in the format "host:port/service_name".
        Example: "dbserver.example.com:1521/ORCLPDB1"

    user : str
        Oracle database username.

    password : str
        Oracle database password.

    workers : int, default=6
        Number of parallel threads to run.
        Must be ≤ the max size of the SessionPool.

    chunk_size : int, default=1000
        Number of IDs per SQL query chunk.
        Oracle typically handles IN lists up to ~1000 items reliably.

    Returns
    -------
    list[tuple]
        A list of tuples, each containing:
        (id, fips, UI, run, wage, yr_qtr)
        Example:
        [
            (101, '12345', 'UI001', 'run1', 55000, '2023-1'),
            (205, '67890', 'UI002', 'run2', 62000, '2024-2')
        ]

    Notes
    -----
    - Filtering is done at numeric (year, qtr) level to ensure correct ordering across years.
    - `yr_qtr` is formatted as "YYYY-Q", but can be zero-padded (YYYY-01) if required for sorting.
    - Performance depends on `chunk_size`, `workers`, and database capacity.
    """
