

def dupesum(df,id_col="id",wage_col="WAGE"):
    if id_col not in df.columns:
        raise ValueError(f"Missing column: {id_col}")
    if wage_col not in df.columns:
        raise ValueError(f"Missing column: {wage_col}")
    df=df.copy()
    df[wage_col]=pd.to_numeric(df[wage_col],errors="coerce").fillna(0)
    agg={}
    for c in df.columns:
        if c==wage_col:
            agg[c]="sum"
        elif c==id_col:
            agg[c]="first"
        else:
            agg[c]="first"
    out=df.groupby(id_col,as_index=False).agg(agg)
    return out
dupesum(df,"ID","WAGE")


import pandas as pd
from pathlib import Path
from collections import Counter

def top_id_occurrences_in_dir(folder_path,id_col="id",top_n=20,common_only=False,chunk_size=250_000):
    folder=Path(folder_path)
    files=sorted(folder.glob("*.csv"))
    if not files:
        raise ValueError("No CSV files found")
    common_ids=None
    if common_only:
        for f in files:
            s=set()
            for ch in pd.read_csv(f,usecols=[id_col],chunksize=chunk_size):
                s|=set(ch[id_col].dropna().astype(str))
            common_ids=s if common_ids is None else (common_ids&s)
            if not common_ids:
                break
        if not common_ids:
            return pd.DataFrame(columns=["id","total_count","file_count","files"])
    total=Counter()
    file_counts=Counter()
    id_files={}
    for f in files:
        c=Counter()
        for ch in pd.read_csv(f,usecols=[id_col],chunksize=chunk_size):
            ids=ch[id_col].dropna().astype(str)
            if common_only:
                ids=ids[ids.isin(common_ids)]
            c.update(ids.tolist())
        if c:
            total.update(c)
            file_counts.update({k:1 for k in c.keys()})
            for k in c.keys():
                id_files.setdefault(k,[]).append(f.name)
    top=total.most_common(top_n)
    rows=[]
    for k,v in top:
        rows.append({"id":k,"total_count":v,"file_count":file_counts.get(k,0),"files":",".join(id_files.get(k,[]))})
    return pd.DataFrame(rows)

df_top=top_id_occurrences_in_dir("data/csvs",id_col="ID",top_n=20)
df_common_top=top_id_occurrences_in_dir("data/csvs",id_col="ID",top_n=20,common_only=True)
