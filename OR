import pandas as pd
import polars as pl
import us
from openpyxl import Workbook

def build_naics_xlsx(year, quarter, output_path):
    states = ['AL','AR','CT','FL','GA','IA','IL','IN','ID','KS','LA','MD','ME','MN',
              'MT','NE','NJ','NM','OH','OK','OR','PA','RI','SC','SD','WA','WI','WV',
              'WY','TX','UT']
    
    def abbr2fips(abbr):
        return us.states.lookup(abbr).fips.lstrip("0")
    
    fips_list = [abbr2fips(s) for s in states]

    # collect all state DF
    state_dfs = []
    for st, f in zip(states, fips_list):
        print(f"Processing {st} {year} Q{quarter} ...")
        dom = Fetch_DOM_QTR(year, quarter, f)
        if dom.empty:
            print(f"Skipping: {st} empty DOM")
            continue
        dom["state"] = st
        state_dfs.append(dom)

    # US-combined table
    us_all = pd.concat(state_dfs, ignore_index=True)

    # NAICS fields + mapping
    naics_cols = ["naics2", "naics3", "naics4", "naics5", "naics6"]

    def agg_lvl(code):
        l = len(str(code))
        if l == 2: return 55
        if l == 3: return 56
        if l == 4: return 57
        if l == 5: return 58
        if l == 6: return 59
        return None

    # build an empty list to collect all rows
    master_rows = []

    # For each state
    for st in states:
        sdf = us_all[us_all["state"] == st]
        if sdf.empty:
            continue
        total_s = len(sdf)

        # loop NAICS levels
        for col in naics_cols:
            sub = sdf.groupby(col).size().reset_index(name="count")
            sub["pct"] = (sub["count"] / total_s * 100).round(2)
            sub["naics"] = sub[col].astype(str)
            sub["agg_lvl"] = sub["naics"].apply(agg_lvl)

            # create rows: one per NAICS per state
            for _, r in sub.iterrows():
                master_rows.append({
                    "naics": r["naics"],
                    "agg_lvl": r["agg_lvl"],
                    f"{st}_count": r["count"],
                    f"{st}_pct": r["pct"]
                })

    # Convert to DF
    df = pd.DataFrame(master_rows)

    # aggregate over duplicates (multiple states merged)
    df = df.groupby(["naics","agg_lvl"], as_index=False).agg("sum")

    # add U.S. totals
    us_totals = {}

    total_us = len(us_all)

    for col in naics_cols:
        sub = us_all.groupby(col).size().reset_index(name="count")
        sub["pct"] = (sub["count"] / total_us * 100).round(2)
        sub["naics"] = sub[col].astype(str)
        sub["agg_lvl"] = sub["naics"].apply(agg_lvl)
        for _, r in sub.iterrows():
            us_totals.setdefault((r["naics"], r["agg_lvl"]), {})
            us_totals[(r["naics"], r["agg_lvl"])]["US_count"] = r["count"]
            us_totals[(r["naics"], r["agg_lvl"])]["US_pct"] = r["pct"]

    # merge US totals
    us_df = pd.DataFrame(
        [
            {"naics": k[0], "agg_lvl": k[1], **v}
            for k, v in us_totals.items()
        ]
    )

    final = df.merge(us_df, on=["naics","agg_lvl"], how="outer")

    # sort nicely
    final = final.sort_values(["agg_lvl","naics"])

    # output XLSX
    final.to_excel(output_path, index=False)
    print(f"Saved: {output_path}")
