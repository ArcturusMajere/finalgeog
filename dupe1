import pandas as pd

# Sample DataFrame
data = {
    'ID': [1, 2, 2, 3, 4, 4],
    'wage': [50000, 60000, 65000, 70000, 45000, 47000]
}
df = pd.DataFrame(data)

# Group by ID and keep the row with the maximum wage for each group
result_df = df.loc[df.groupby('ID')['wage'].idxmax()]

# Reset index if necessary
result_df = result_df.reset_index(drop=True)

print(result_df)


def subset_and_order_duplicates(df, id_column, wage_column):
    """
    Subsets all rows with duplicate IDs and orders them by ID and Wage in descending order.

    Parameters:
    df (pd.DataFrame): The input DataFrame.
    id_column (str): The column name representing IDs.
    wage_column (str): The column name representing wages.

    Returns:
    pd.DataFrame: A DataFrame containing duplicate IDs and their wages, sorted by ID and Wage in descending order.
    """
    # Identify duplicate IDs
    duplicate_ids = df[id_column].duplicated(keep=False)
    
    # Subset rows with duplicate IDs
    duplicates_df = df[duplicate_ids]
    
    # Sort by ID and Wage in descending order
    sorted_duplicates_df = duplicates_df.sort_values(by=[id_column, wage_column], ascending=[False, False])
    
    return sorted_duplicates_df

