{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae31d9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DOM4(year,qtr,fips):\n",
    "    host = 'dbeslinx'; DOM3 = []\n",
    "    dnaicsloc = \"/wagerec/current_dominantnaics/parquet/\"\n",
    "    fs = SSHFileSystem(host,username=USER,password=PWD,)\n",
    "    tds = ds.dataset(dnaicsloc, filesystem=fs)\n",
    "    DOM1 = pl.scan_pyarrow_dataset(tds)\n",
    "    DOM2 = (DOM1.filter(pl.col('fips') == fips).filter(pl.col('year') == year)\n",
    "        .filter(pl.col('qtr') == qtr)).filter(pl.col('Dui_level')==True))\n",
    "    Final = DOM2.select(['ui_acct','fips','naics4']).collect().to_pandas()\n",
    "    Final.rename(columns={'ui_acct': 'UI'},inplace=True)\n",
    "    print(f\"{Final.shape[0]} Dominant Naics records found\")\n",
    "    return(Final)\n",
    "\n",
    "def extraction(state, quarter, year):\n",
    "    fips = US.get(state);f=fips.lstrip('0')\n",
    "    domnaics = DOM4(year,quarter,f)\n",
    "    params={'state':fips,'year':year,'qtr':quarter}\n",
    "    WR = pd.read_sql(query,con=conn,params=params)\n",
    "    WR['fips']=WR['STATE_CODE'].astype(str)\n",
    "    WR['RUN'] = WR['RUN'].astype(str)\n",
    "    WR['UI'] = WR['UI'].astype(str)\n",
    "    domnaics['RUN'] = domnaics['RUN'].astype(str)\n",
    "    domnaics['UI'] = domnaics['UI'].astype(str)\n",
    "    B=getbad(BAD,year,quarter)\n",
    "    WR,domnaics=clean(WR,domnaics,B)\n",
    "    WR=dupeID(WR)\n",
    "    A = Cmerge(WR,domnaics)\n",
    "    return A\n",
    "\n",
    "def get_cohort(state, quarter, year):\n",
    "    A = extraction(state, quarter, year)\n",
    "    B = A[A['naics4'] == '6244']\n",
    "    T = B['BLS_ID'].tolist()\n",
    "    file_wage = os.path.join('/moving_sale/B/coh', f'{year}', f'wages_{state}.csv')\n",
    "    B.to_csv(file_wage, index=True)\n",
    "    return T\n",
    "\n",
    "def LOOK(state, year, quarter, cohort):\n",
    "    A = exctraction(state,quarter,year)\n",
    "    matches = A[A['BLS_ID'].isin(cohort)]\n",
    "    file_wage = os.path.join('/moving_sale/B/coh', f'{year}', f'wages_{state}.csv')\n",
    "    matches.to_csv(file_wage, index=True)\n",
    "    print(f\"{matches.shape[0]} {state} matches found in {year} {quarter}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e1ffee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import threading\n",
    "\n",
    "initial_state = 'TX'  \n",
    "initial_year = 2019\n",
    "initial_quarter = 2\n",
    "initial_cohort = get_cohort(initial_state, initial_quarter, initial_year)\n",
    "\n",
    "quarters = []\n",
    "year = 2019\n",
    "quarter = 3\n",
    "while not (year == 2024 and quarter == 2):\n",
    "    quarters.append((year, quarter))\n",
    "    quarter += 1\n",
    "    if quarter > 4:\n",
    "        quarter = 1\n",
    "        year += 1\n",
    "\n",
    "\n",
    "all_states = US.get_states()  \n",
    "\n",
    "def worker(state, year, quarter, cohort):\n",
    "    LOOK(state, year, quarter, cohort)\n",
    "\n",
    "threads = []\n",
    "\n",
    "for state in all_states:\n",
    "    for year, quarter in quarters:\n",
    "        t = threading.Thread(target=worker, args=(state, year, quarter, initial_cohort))\n",
    "        threads.append(t)\n",
    "        t.start()\n",
    "\n",
    "for t in threads:\n",
    "    t.join()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
